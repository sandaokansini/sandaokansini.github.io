<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Logistic回归</title>
    <link href="/2024/10/19/Logistic%E5%9B%9E%E5%BD%92/"/>
    <url>/2024/10/19/Logistic%E5%9B%9E%E5%BD%92/</url>
    
    <content type="html"><![CDATA[<h1>Logistic回归</h1><h2 id="定义">定义</h2><p>线性回归精辟再加一层logistic函数的调用<br>主要进行二分类预测</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>滑坡实验</title>
    <link href="/2024/10/17/%E6%BB%91%E5%9D%A1%E5%AE%9E%E9%AA%8C/"/>
    <url>/2024/10/17/%E6%BB%91%E5%9D%A1%E5%AE%9E%E9%AA%8C/</url>
    
    <content type="html"><![CDATA[<h1>RF</h1><p><a href="https://blog.csdn.net/cxyxx12/article/details/134415329">代码基于此博客</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix, classification_report, accuracy_score<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> ShuffleSplit, cross_val_score, LeaveOneOut, StratifiedShuffleSplit<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> export_graphviz<br><span class="hljs-keyword">import</span> graphviz<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> os<br><span class="hljs-comment"># os.environ[&quot;PATH&quot;] += os.pathsep + r&#x27; D:\APP\anaconda\envs\pytorch\Library\bin\graphviz\config6&#x27;</span><br><br><span class="hljs-comment"># 加载数据</span><br>df_X = pd.read_excel(<span class="hljs-string">&#x27;DataX.xlsx&#x27;</span>)<br>feature_names = df_X.columns.tolist()  <span class="hljs-comment"># 将文件列名转换为Python列表</span><br><br><br>X = df_X.values  <span class="hljs-comment"># 输入特征，返回给定DataFrame的Numpy表现形式</span><br><br>y = pd.DataFrame(pd.read_excel(<span class="hljs-string">&#x27;DataY.xlsx&#x27;</span>)).values.ravel()  <span class="hljs-comment"># 目标变量</span><br><br><span class="hljs-comment"># 创建随机森林分类器</span><br><span class="hljs-comment"># clf = RandomForestClassifier(n_estimators=100)</span><br>clf = RandomForestClassifier(class_weight=<span class="hljs-string">&#x27;balanced&#x27;</span>,<br>                             n_estimators=<span class="hljs-number">100</span>,  <span class="hljs-comment"># 树的数量</span><br>                             <span class="hljs-comment"># max_depth=10,  # 树的最大深度,设置后欠拟合</span><br>                             min_samples_split=<span class="hljs-number">2</span>,  <span class="hljs-comment"># 节点分裂所需的最小样本数</span><br>                             min_samples_leaf=<span class="hljs-number">1</span>  <span class="hljs-comment"># 叶节点的最小样本数</span><br>                             )<br><br><span class="hljs-comment"># 创建ShuffleSplit对象，用于执行自动洗牌</span><br><span class="hljs-comment"># ss = ShuffleSplit(n_splits=5, train_size=0.7, test_size=0.3, random_state=0)  # n_split:划分次数</span><br>ss = StratifiedShuffleSplit(n_splits=<span class="hljs-number">1</span>, test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">0</span>)  <span class="hljs-comment"># 实现分层、随机采样</span><br><br>accuracies = []<br>split = <span class="hljs-number">0</span><br><br><span class="hljs-comment"># 循环遍历每个拆分，并使用随机森林分类器对每个拆分进行训练和评估</span><br><span class="hljs-keyword">for</span> train_index, test_index <span class="hljs-keyword">in</span> ss.split(X, y):<br>    X_train, X_test = X[train_index], X[test_index]<br>    y_train, y_test = y[train_index], y[test_index]<br>    clf.fit(X_train, y_train)<br><br>    <span class="hljs-comment"># 评估训练集</span><br>    y_train_pred = clf.predict(X_train)<br>    train_acc = accuracy_score(y_train, y_train_pred)<br><br>    <span class="hljs-comment"># 评估测试集</span><br>    y_pred = clf.predict(X_test)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Confusion Matrix:&quot;</span>)<br>    <span class="hljs-built_in">print</span>(confusion_matrix(y_test, y_pred))  <span class="hljs-comment"># 输出分类结果矩阵</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Classification Report:&quot;</span>)<br>    <span class="hljs-built_in">print</span>(classification_report(y_test, y_pred))  <span class="hljs-comment"># 输出混淆矩阵</span><br>    acc = accuracy_score(y_test, y_pred)<br>    accuracies.append(acc)<br>    split += <span class="hljs-number">1</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Training/Testing Accuracy for <span class="hljs-subst">&#123;split&#125;</span> split : <span class="hljs-subst">&#123;train_acc, acc&#125;</span>&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Average accuracy over <span class="hljs-subst">&#123;ss.get_n_splits()&#125;</span> splits: <span class="hljs-subst">&#123;<span class="hljs-built_in">sum</span>(accuracies) / <span class="hljs-built_in">len</span>(accuracies)&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># # 5折交叉验证</span><br><span class="hljs-comment"># cv_scores = cross_val_score(clf, X, y, cv=5, scoring=&#x27;accuracy&#x27;)  # cv=5 表示5折交叉验证</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># # 输出每次的得分和平均准确率</span><br><span class="hljs-comment"># print(&quot;Cross-validation scores for each fold:&quot;, cv_scores)</span><br><span class="hljs-comment"># print(&quot;Average accuracy:&quot;, cv_scores.mean())  # 0.52</span><br><br><span class="hljs-comment"># # 留一法交叉验证， 运行时间太长，别运行</span><br><span class="hljs-comment"># loo = LeaveOneOut()</span><br><span class="hljs-comment"># loo_scores = cross_val_score(clf, X, y, cv=loo, scoring=&#x27;accuracy&#x27;)</span><br><span class="hljs-comment"># print(f&quot;Average accuracy with LOO: &#123;loo_scores.mean()&#125;&quot;)</span><br><br><br><span class="hljs-comment"># 特征重要性</span><br>importances = clf.feature_importances_<br><span class="hljs-built_in">print</span>(importances)<br><br><span class="hljs-comment"># 画条形图</span><br>plt.barh(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(importances)), importances)<br><br><span class="hljs-comment"># 添加标题和特征名称</span><br>plt.title(<span class="hljs-string">&quot;Feature Importances&quot;</span>)<br>plt.yticks(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(importances)), feature_names)  <span class="hljs-comment"># 确保特征名称与特征数一致</span><br><br><span class="hljs-comment"># 保存图像</span><br>plt.savefig(<span class="hljs-string">&#x27;feature_importance.png&#x27;</span>)<br><br><span class="hljs-comment"># 可视化随机森林中的一棵树</span><br>dot_data = export_graphviz(clf.estimators_[<span class="hljs-number">0</span>], out_file=<span class="hljs-literal">None</span>,<br>                           feature_names=feature_names)<br><br><span class="hljs-comment"># 使用 graphviz 库读取 dot 文件并生成决策树可视化图形</span><br>graph = graphviz.Source(dot_data)<br>graph.render(<span class="hljs-string">&#x27;decision_tree&#x27;</span>)<br><br><br></code></pre></td></tr></table></figure><h1>SVM</h1><p><a href="https://blog.csdn.net/cxyxx12/article/details/134415329">代码基于此博客</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> svm<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">SVM参数</span><br><span class="hljs-string">C:惩罚系数，越高越不能容易出现误差，容易过拟合（越小则容易欠拟合）(但是此模型提高C不能改善欠拟合）</span><br><span class="hljs-string">gamma：选择径向基函数（RBF）作为kernel后，该函数自带的一个参数，gamma越大，支持向量越少，gamma越小，支持向量越多</span><br><span class="hljs-string"></span><br><span class="hljs-string">核函数：</span><br><span class="hljs-string">线性核Linear</span><br><span class="hljs-string">多项式核Poly</span><br><span class="hljs-string">高斯核rbf</span><br><span class="hljs-string">拉普拉斯核</span><br><span class="hljs-string">Sigmoid核</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>svm.SVC(<br>    C=<span class="hljs-number">1.0</span>,<br>    kernel=<span class="hljs-string">&#x27;rbf&#x27;</span>,<br>    gamma=<span class="hljs-string">&#x27;scale&#x27;</span><br>)<br>df = pd.read_excel(<span class="hljs-string">&#x27;MLinput.xlsx&#x27;</span>)<br><span class="hljs-comment"># 去除后accuracy变低了</span><br><span class="hljs-comment"># df = df.drop([&#x27;X&#x27;, &#x27;Y&#x27;, &#x27;Z&#x27;, &#x27;sca&#x27;], axis=1)</span><br><br>feature = df.columns.tolist()<br><span class="hljs-keyword">del</span> feature[<span class="hljs-number">0</span>]<br><span class="hljs-comment"># print(feature)</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">3、滑坡/非滑坡数量情况统计</span><br><span class="hljs-string">观察样本集 非滑坡:0 与 滑坡:1 数量情况</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><br>sns.countplot(x=df[<span class="hljs-string">&#x27;class&#x27;</span>])<br><span class="hljs-comment"># plt.show()</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">筛选特征--&gt;降维</span><br><span class="hljs-string">特征里面两两特征之间的相关性</span><br><span class="hljs-string">    - 相关程度非常高：选择其中一个作为代表即可</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>feature_corr = df[feature].corr()<br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">来进行相关性的可视化</span><br><span class="hljs-string">- 热力图：颜色越浅说明相关程度越大</span><br><span class="hljs-string">    - annot=True--&gt;显示每个方格的数据</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>plt.figure(figsize=(<span class="hljs-number">14</span>, <span class="hljs-number">8</span>))<br>sns.heatmap(feature_corr, annot=<span class="hljs-literal">False</span>)<br><span class="hljs-comment"># plt.show()</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">4  数据分割</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><br>train, test = train_test_split(df, test_size=<span class="hljs-number">0.3</span>)  <span class="hljs-comment"># 纯随机采样</span><br>train_X = train[feature]<br>test_X = test[feature]<br><span class="hljs-comment"># 构建 标签</span><br>train_y = train[<span class="hljs-string">&#x27;class&#x27;</span>]<br>y_test = test[<span class="hljs-string">&#x27;class&#x27;</span>]<br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">5  数据归一化</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><br>ss = StandardScaler()<br>train_X = ss.fit_transform(train_X)<br>test_X = ss.fit_transform(test_X)<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">6  模型训练及预测</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC<br>model = SVC()<br>model.fit(train_X, train_y)<br><br>y_pred = model.predict(test_X)<br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">7 模型评价</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix, classification_report, accuracy_score<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Confusion Matrix:&quot;</span>)<br><span class="hljs-built_in">print</span>(confusion_matrix(y_test, y_pred))  <span class="hljs-comment"># 输出分类结果矩阵</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Classification Report:&quot;</span>)<br><span class="hljs-built_in">print</span>(classification_report(y_test, y_pred))  <span class="hljs-comment"># 输出混淆矩阵</span><br><br>train_acc = model.score(train_X, train_y)  <span class="hljs-comment"># 内联函数</span><br>acc = accuracy_score(y_test, y_pred)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Training/Testing Accuracy: <span class="hljs-subst">&#123;train_acc, acc&#125;</span>&#x27;</span>)  <span class="hljs-comment"># 0.6293</span><br></code></pre></td></tr></table></figure><h1>LR</h1><p>代码基于此博客SVM</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV<br><br>LR = LogisticRegression()<br><br><br>param_grid = &#123;<br>    <span class="hljs-string">&#x27;C&#x27;</span>: [<span class="hljs-number">1</span>],<br>    <span class="hljs-string">&#x27;penalty&#x27;</span>: [<span class="hljs-string">&#x27;l1&#x27;</span>],  <span class="hljs-comment"># 决定正则化类型</span><br>    <span class="hljs-string">&#x27;solver&#x27;</span>: [<span class="hljs-string">&#x27;liblinear&#x27;</span>],  <span class="hljs-comment"># 决定优化算法</span><br>    <span class="hljs-string">&#x27;max_iter&#x27;</span>: [<span class="hljs-number">1000</span>]<br>&#125;<br><span class="hljs-comment"># 自动化参数调优</span><br>grid_search = GridSearchCV(LR, param_grid, cv=<span class="hljs-number">5</span>)<br><br>df = pd.read_excel(<span class="hljs-string">&#x27;MLinput.xlsx&#x27;</span>)<br><br>feature = df.columns.tolist()<br><span class="hljs-keyword">del</span> feature[<span class="hljs-number">0</span>]<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">4  数据分割</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><br>train, test = train_test_split(df, test_size=<span class="hljs-number">0.3</span>)  <span class="hljs-comment"># 纯随机采样</span><br>train_X = train[feature]<br>test_X = test[feature]<br><span class="hljs-comment"># 构建 标签</span><br>train_y = train[<span class="hljs-string">&#x27;class&#x27;</span>]<br>y_test = test[<span class="hljs-string">&#x27;class&#x27;</span>]<br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">5  数据归一化</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><br>ss = StandardScaler()<br>train_X = ss.fit_transform(train_X)<br>test_X = ss.fit_transform(test_X)<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">6  寻找最佳参数,训练模型</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>grid_search.fit(train_X, train_y)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Best parameters:&quot;</span>, grid_search.best_params_)<br><span class="hljs-comment"># 使用最优模型进行预测</span><br>best_model = grid_search.best_estimator_<br>y_pred = best_model.predict(test_X)<br><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">7 模型评价</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix, classification_report, accuracy_score<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Confusion Matrix:&quot;</span>)<br><span class="hljs-built_in">print</span>(confusion_matrix(y_test, y_pred))  <span class="hljs-comment"># 输出分类结果矩阵</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Classification Report:&quot;</span>)<br><span class="hljs-built_in">print</span>(classification_report(y_test, y_pred))  <span class="hljs-comment"># 输出混淆矩阵</span><br><br>train_acc = best_model.score(train_X, train_y)  <span class="hljs-comment"># 内联函数</span><br>acc = accuracy_score(y_test, y_pred)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Training/Testing Accuracy: <span class="hljs-subst">&#123;train_acc, acc&#125;</span>&#x27;</span>)  <span class="hljs-comment"># 0.6239</span><br></code></pre></td></tr></table></figure><h1>分类器筛选</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-keyword">from</span> sklearn.ensemble import RandomForestClassifier<br><span class="hljs-keyword">from</span> sklearn.linear_model import LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.svm import SVC<br><span class="hljs-keyword">from</span> sklearn.neighbors import KNeighborsClassifier<br><span class="hljs-keyword">from</span> sklearn.tree import DecisionTreeClassifier, export_graphviz<br><span class="hljs-keyword">from</span> sklearn.metrics import confusion_matrix, classification_report, accuracy_score<br><span class="hljs-keyword">from</span> sklearn.model_selection import ShuffleSplit, cross_val_score, LeaveOneOut, StratifiedShuffleSplit<br>import pandas as pd<br><span class="hljs-keyword">from</span> sklearn.preprocessing import StandardScaler<br><span class="hljs-keyword">from</span> sklearn.ensemble import GradientBoostingClassifier<br><span class="hljs-keyword">from</span> xgboost import XGBClassifier<br><span class="hljs-keyword">from</span> sklearn.ensemble import AdaBoostClassifier<br><span class="hljs-keyword">from</span> lightgbm import LGBMClassifier<br><span class="hljs-keyword">from</span> sklearn.neural_network import MLPClassifier<br><br><br><span class="hljs-comment"># # 加载数据</span><br><span class="hljs-comment"># df1 = pd.read_excel(&#x27;DataX.xlsx&#x27;)</span><br><span class="hljs-comment"># XX = df1.values  # 输入特征，返回给定DataFrame的Numpy表现形式</span><br><span class="hljs-comment"># feature_names = df1.columns.tolist()  # 将文件列名转换为Python列表</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># df2 = pd.read_excel(&#x27;DataY.xlsx&#x27;)</span><br><span class="hljs-comment"># yy = df2.values.ravel()  # 目标变量</span><br><br>data = pd.read_csv(<span class="hljs-string">&#x27;sxcoor.csv&#x27;</span>)<br><span class="hljs-comment"># 假设最后一列是标签，前面的列是特征</span><br>XX = data.iloc[1:, 1:].values  # 特征<br>yy = data.iloc[1:, 0].values   # 标签<br><br>s = StratifiedShuffleSplit(<span class="hljs-attribute">n_splits</span>=1, <span class="hljs-attribute">test_size</span>=0.5, <span class="hljs-attribute">random_state</span>=0)<br><br><span class="hljs-keyword">for</span> half1, half2 <span class="hljs-keyword">in</span> s.split(XX, yy):<br>    X, new_data = XX[half1], XX[half2]<br>    y, new_data_y = yy[half1], yy[half2]<br><br><br><span class="hljs-comment"># 用于存储准确率大于 0.7 的模型及其最佳参数</span><br>qualified_models = &#123;&#125;<br><br><span class="hljs-comment"># 创建随机森林分类器</span><br><span class="hljs-comment"># clf = RandomForestClassifier(n_estimators=100)</span><br>RF = RandomForestClassifier(<span class="hljs-attribute">class_weight</span>=<span class="hljs-string">&#x27;balanced&#x27;</span>,<br>                             <span class="hljs-attribute">n_estimators</span>=100,  # 树的数量<br>                             # <span class="hljs-attribute">max_depth</span>=10,  # 树的最大深度,设置后欠拟合<br>                             <span class="hljs-attribute">min_samples_split</span>=2,  # 节点分裂所需的最小样本数<br>                             <span class="hljs-attribute">min_samples_leaf</span>=1  # 叶节点的最小样本数<br>                             )<br><br><br>LR = LogisticRegression(<span class="hljs-attribute">C</span>=1, <span class="hljs-attribute">penalty</span>=<span class="hljs-string">&#x27;l1&#x27;</span>, <span class="hljs-attribute">solver</span>=<span class="hljs-string">&#x27;liblinear&#x27;</span>, <span class="hljs-attribute">max_iter</span>=1000)<br><br>SVM = SVC(<br>    <span class="hljs-attribute">C</span>=1.0,<br>    <span class="hljs-attribute">kernel</span>=<span class="hljs-string">&#x27;rbf&#x27;</span>,<br>    <span class="hljs-attribute">gamma</span>=<span class="hljs-string">&#x27;scale&#x27;</span><br>)<br><br>KNN = KNeighborsClassifier(<span class="hljs-attribute">n_neighbors</span>=6)<br><br>DT = DecisionTreeClassifier(<span class="hljs-attribute">random_state</span>=42)<br><br>GBC = GradientBoostingClassifier(<span class="hljs-attribute">n_estimators</span>=100, <span class="hljs-attribute">learning_rate</span>=0.1, <span class="hljs-attribute">max_depth</span>=3, <span class="hljs-attribute">random_state</span>=42)<br><br>XGB = XGBClassifier(<span class="hljs-attribute">n_estimators</span>=100, <span class="hljs-attribute">learning_rate</span>=0.1, <span class="hljs-attribute">max_depth</span>=3, <span class="hljs-attribute">random_state</span>=42)<br><br>ABC = AdaBoostClassifier(<span class="hljs-attribute">n_estimators</span>=100, <span class="hljs-attribute">random_state</span>=42)<br><br>LGBM = LGBMClassifier(<span class="hljs-attribute">n_estimators</span>=100, <span class="hljs-attribute">num_leaves</span>=31, <span class="hljs-attribute">max_depth</span>=-1, <span class="hljs-attribute">learning_rate</span>=0.1, <span class="hljs-attribute">random_state</span>=42,<br>                      <span class="hljs-attribute">force_col_wise</span>=<span class="hljs-string">&#x27;true&#x27;</span>)<br><br>MLP = MLPClassifier(hidden_layer_sizes=(100,), <span class="hljs-attribute">max_iter</span>=500, <span class="hljs-attribute">activation</span>=<span class="hljs-string">&#x27;relu&#x27;</span>, <span class="hljs-attribute">solver</span>=<span class="hljs-string">&#x27;adam&#x27;</span>, <span class="hljs-attribute">random_state</span>=42)<br><br>model = &#123;<br>    <span class="hljs-string">&#x27;RF&#x27;</span>: RF,<br>    <span class="hljs-string">&#x27;LR&#x27;</span>: LR,<br>    <span class="hljs-string">&#x27;SVM&#x27;</span>: SVM,<br>    <span class="hljs-string">&#x27;KNN&#x27;</span>: KNN,<br>    <span class="hljs-string">&#x27;DT&#x27;</span>: DT,<br>    <span class="hljs-string">&#x27;GBC&#x27;</span>: GBC,<br>    <span class="hljs-string">&#x27;XGB&#x27;</span>: XGB,<br>    <span class="hljs-string">&#x27;MLP&#x27;</span>: MLP,<br>    <span class="hljs-string">&#x27;ABC&#x27;</span>: ABC,<br>    <span class="hljs-string">&#x27;LGBM&#x27;</span>: LGBM<br>&#125;<br><br><span class="hljs-comment"># 创建ShuffleSplit对象，用于执行自动洗牌</span><br>ss = StratifiedShuffleSplit(<span class="hljs-attribute">n_splits</span>=1, <span class="hljs-attribute">test_size</span>=0.3, <span class="hljs-attribute">random_state</span>=0)  # 实现分层、随机采样<br><br>scaler = StandardScaler()<br><span class="hljs-keyword">for</span> name, clf <span class="hljs-keyword">in</span> model.items():<br><br>    accuracies = []<br>    split = 0<br><br>    # 循环遍历每个拆分，并使用随机森林分类器对每个拆分进行训练和评估<br>    <span class="hljs-keyword">for</span> train_index, test_index <span class="hljs-keyword">in</span> ss.split(X, y):<br>        X_train, X_test = X[train_index], X[test_index]<br>        y_train, y_test = y[train_index], y[test_index]<br><br>        # 树形模型不需要归一化<br>        <span class="hljs-keyword">if</span> name != <span class="hljs-string">&#x27;RF&#x27;</span> <span class="hljs-keyword">and</span> name != <span class="hljs-string">&#x27;DT&#x27;</span>:<br><br>            X_train = scaler.fit_transform(X_train)<br>            X_test = scaler.transform(X_test)<br><br>        clf.fit(X_train, y_train)<br><br>        # 评估训练集<br>        y_train_pred = clf.predict(X_train)<br>        train_acc = accuracy_score(y_train, y_train_pred)<br><br>        # 评估测试集<br>        y_pred = clf.predict(X_test)<br>        acc = accuracy_score(y_test, y_pred)<br>        accuracies.append(acc)<br>        split += 1<br>        # 筛选准确率大于 0.69 的模型<br><br>        # <span class="hljs-built_in">print</span>(f<span class="hljs-string">&#x27;Training/Testing Accuracy for &#123;split&#125; split : &#123;train_acc, acc&#125;&#x27;</span>)<br>    accuracy = sum(accuracies) / len(accuracies)<br>    <span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;&#123;clf.__class__.__name__&#125; learner Average accuracy over &#123;split&#125; splits: &#123;accuracy&#125;&quot;</span>)<br>    <span class="hljs-keyword">if</span> accuracy &gt;= 0.69:<br>        qualified_models[name] = clf<br>        <span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;&#123;name&#125; 模型被选为合格模型&quot;</span>)<br><br><span class="hljs-keyword">for</span> name, clf <span class="hljs-keyword">in</span> qualified_models.items():<br>    <span class="hljs-keyword">if</span> name != <span class="hljs-string">&#x27;RF&#x27;</span> <span class="hljs-keyword">and</span> name != <span class="hljs-string">&#x27;DT&#x27;</span>:<br>        new_data_scaled = scaler.transform(new_data)<br>    <span class="hljs-keyword">else</span>:<br>        new_data_scaled = new_data<br>    new_predictions = clf.predict(new_data_scaled)<br>    acc = accuracy_score(new_data_y, new_predictions)<br>    <span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;&#123;name&#125; Accuracy: &#123;acc&#125;&quot;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>基于物理数据的数据驱动模型用于三峡库区滑坡易发性评估</title>
    <link href="/2024/10/17/%E5%9F%BA%E4%BA%8E%E7%89%A9%E7%90%86%E6%95%B0%E6%8D%AE%E7%9A%84%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E6%A8%A1%E5%9E%8B%E7%94%A8%E4%BA%8E%E4%B8%89%E5%B3%A1%E5%BA%93%E5%8C%BA%E6%BB%91%E5%9D%A1%E6%98%93%E5%8F%91%E6%80%A7%E8%AF%84%E4%BC%B0/"/>
    <url>/2024/10/17/%E5%9F%BA%E4%BA%8E%E7%89%A9%E7%90%86%E6%95%B0%E6%8D%AE%E7%9A%84%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E6%A8%A1%E5%9E%8B%E7%94%A8%E4%BA%8E%E4%B8%89%E5%B3%A1%E5%BA%93%E5%8C%BA%E6%BB%91%E5%9D%A1%E6%98%93%E5%8F%91%E6%80%A7%E8%AF%84%E4%BC%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="文献推荐链接"><a href="https://mp.weixin.qq.com/s/3fUJaTqLTu-UgQkbqGmKxw">文献推荐链接</a></h2><p><a href="https://www.sciencedirect.com/science/article/pii/S1674987123000889?ref=pdf_download&amp;fr=RR-2&amp;rr=8d341b785e93ddc2#ab010">原文链接</a></p><h2 id="总述">总述</h2><p><img src="/image/%E6%B5%81%E7%A8%8B%E5%9B%BE.jpg" alt=""></p><p>|数据处理|预测模型|评估方法|<br>|Scoops 3D|随机森林法|AUC|</p><p>问题：非滑坡样本的生成<br>解决现状：分形理论模型生成的低坡区、无滑坡区和极低易发区的随机选择</p><p>Scoops 3D：一种具有很高的可解释性的物理方法，三维极限平衡方法，考虑了边坡的几何形状、材料特性和边界条件</p><h3 id="数据">数据</h3><p>研究区域：巴东县、秭归县；<br>方法：ArcGIS处理、提取收集的数据，将处理后的土地深度数据和相应的岩土参数输入到Scoops 3D，（安全系数）FS大于1.5被随机选择为负样本，从而建立完整数据集<br>数据收集：影响因子根据过往经验选取<br><img src="/image/%E5%BD%B1%E5%93%8D%E5%9B%A0%E5%AD%90.png" alt=""><br>数据处理：使用ArcGIS</p>]]></content>
    
    
    
    <tags>
      
      <tag>文献</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>搭建指南</title>
    <link href="/2024/10/16/%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97/"/>
    <url>/2024/10/16/%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/yaorongke/article/details/119089190?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522DEC1D3C5-1243-434F-A99D-A0CFCB1371B1%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=DEC1D3C5-1243-434F-A99D-A0CFCB1371B1&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-119089190-null-null.142%5Ev100%5Epc_search_result_base8&amp;utm_term=github%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99&amp;spm=1018.2226.3001.4187">hexo配置指南</a><br><a href="https://hexo.fluid-dev.com/docs/guide/#%E5%85%B3%E4%BA%8E%E6%8C%87%E5%8D%97">fluid配置指南</a><br>使用了katex渲染公式</p>]]></content>
    
    
    
    <tags>
      
      <tag>基建</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>重生之我是天才程序员</title>
    <link href="/2024/10/16/%E9%87%8D%E7%94%9F%E4%B9%8B%E6%88%91%E6%98%AF%E5%A4%A9%E6%89%8D%E7%A8%8B%E5%BA%8F%E5%91%98/"/>
    <url>/2024/10/16/%E9%87%8D%E7%94%9F%E4%B9%8B%E6%88%91%E6%98%AF%E5%A4%A9%E6%89%8D%E7%A8%8B%E5%BA%8F%E5%91%98/</url>
    
    <content type="html"><![CDATA[<h1>sandaokansini为何那样</h1><h2 id="10-16之debug顺序">10.16之debug顺序</h2><p>关于配置的问题应该先看<strong>README</strong><br>再网页<strong>搜索</strong><br>实在不行问GPT（不推荐）</p>]]></content>
    
    
    
    <tags>
      
      <tag>日志</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器学习</title>
    <link href="/2024/10/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    <url>/2024/10/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1>机器学习</h1><h2 id="绪论">绪论</h2><p>根据训练数据是否拥有标记信息，学习任务可大致分为<strong>监督学习</strong>（分类、回归）和 <strong>无监督学习</strong>（聚类）<br>聚类：将训练集数据分组，每组称为一个“簇”<br>泛化能力：学得模型适用于新样本的能力</p><h2 id="模型评估与选择">模型评估与选择</h2><p>精度=1-错误率<br><strong>过拟合</strong>：学习器将训练样本自身的特点当作所有潜在样本都具有的性质，导致泛化能力的下降<br>欠拟合：训练样本的一般性质未学好</p><h3 id="评估方法">评估方法</h3><p>将数据集D划分为训练集S和测试集T<br><strong>留出法</strong>：直接将D划分为两个互斥的集合，分层采样<br><strong>交叉验证法</strong>（p次k折交叉验证）：将D划分为k个大小相似的互斥子集，分层采样，每次用k-1个子集的并集作为训练集，剩下的为测试集，共k组训练/测试集，此过程重复p次<br>特例：留一法（LOO，p=k）<br><strong>自助法</strong>：通过<strong>自助采样</strong>生成D’（D中样本不在D’中出现的概率为(（1-<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>m</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>）<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mi>m</mi></msup></mrow><annotation encoding="application/x-tex">^{m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6644em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span></span></span></span></span>=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>e</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{e}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>=0.368），将D’作为训练集（改变初始数据集分布引入偏差），D\D’（:集合减法）作为测试集，使实际评估的模型和期望估计的模型使用训练样本数一致，且约1/3的没在训练集中出现的样本用于测试，这样的测试结果称为<strong>包外估计</strong><br>验证集：模型评估与选择中用于评估测试的数据集</p><h3 id="性能度量">性能度量</h3><p>衡量泛化性能的评估标准<br><strong>错误率与精度accuracy</strong>：相加等于1<br><strong>查准率precision</strong>：P=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{TP}{TP+FP}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">FP</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br><strong>查全率recall</strong>：R=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{TP}{TP+FN}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">FN</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>混淆矩阵（confusion matrix）</p><table><thead><tr><th>正例</th><th>反例</th></tr></thead><tbody><tr><td>TP：true positive真正例</td><td>FP：false positive假正例</td></tr><tr><td>TN：true negative真反例</td><td>FN：false negative假反例</td></tr></tbody></table><p>P-R曲线：面积越大，学习器性能越好<br>平衡点（BEP）：P=R时取值，值越大性能越优</p><p><strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">F_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></strong>=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>2</mn><mo>∗</mo><mi>P</mi><mo>∗</mo><mi>R</mi></mrow><mrow><mi>P</mi><mo>+</mo><mi>R</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{2*P*R}{P+R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mbin mtight">∗</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mbin mtight">∗</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mn>2</mn><mo>∗</mo><mi>T</mi><mi>P</mi></mrow><mrow><mi>m</mi><mo>+</mo><mi>T</mi><mi>P</mi><mo>−</mo><mi>T</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{2*TP}{m+TP-TN}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">TN</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mbin mtight">∗</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br><em><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">F_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>:基于查准率和查全率的调和平均</em><br><em><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>β</mi></msub></mrow><annotation encoding="application/x-tex">F_β</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em;">β</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>：加权调和平均</em></p><p><strong>ROC</strong>：受试者工作特性<br>横轴：假正例率（FPR）=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{FP}{TN+FP}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">TN</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">FP</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">FP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>纵轴：真正例率（TPR）=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{TP}{TP+FN}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">FN</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>用面积大小（即<strong>AUC</strong>）评价性能好坏</p><p><strong>代价敏感错误率与代价曲线</strong><br>代价敏感错误率<br><img src="/image/%E4%BB%A3%E4%BB%B7%E6%95%8F%E6%84%9F%E9%94%99%E8%AF%AF%E7%8E%87.png" alt=""><br>代价曲线图（cost curve）<br>横轴：正例概率代价<br>纵轴：归一化代价<br><a href="https://blog.csdn.net/lg201601/article/details/106200046">具体见</a></p><h3 id="比较检验">比较检验</h3><p><strong>交叉验证t检验</strong><a href="https://blog.csdn.net/orDream/article/details/123409819">解释</a><br><strong>McNemar检验</strong> <a href="https://blog.csdn.net/orDream/article/details/122540099">解释</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>知识库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ArcGIS</title>
    <link href="/2024/10/10/ArcGIS/"/>
    <url>/2024/10/10/ArcGIS/</url>
    
    <content type="html"><![CDATA[<h1>使用ArcGIS处理数据</h1><h2 id="基本步骤">基本步骤</h2><p>1、将需要的数据下载到本地<br>（例：DEM栅格文件）<br>2、栅格文件要素值提取至点，生成包含新的元素的点要素文件</p><h2 id="可能出现的问题">可能出现的问题</h2><p>1、属性表不见了（双屏操作，在边边上拖过来就行了）<br>2、栅格文件导入时闪退（可能与原有点要素文件不兼容，建议更换文件）</p>]]></content>
    
    
    
    <tags>
      
      <tag>知识库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/01/11/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6/"/>
    <url>/2022/01/11/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6/</url>
    
    <content type="html"><![CDATA[<h1>组合数学考试速成</h1><p>第一章、排列与组合</p><ol><li>高中学过的。</li><li>允许重复的组合、不相邻组合、格路模型</li><li>插空法、隔板法。</li><li>排序生成算法（三选一、考定义和具体实操）</li></ol><p>第二章、递推关系和母函数</p><ol><li>给母函数求an</li><li>给递推关系求母函数和an</li><li>给母函数求递推关系</li><li>解常系数齐次递推关系</li><li>司特林数</li></ol><p>第三章、容斥原理和鸽巢原理</p><ol><li>考得容易，基本都是考鸽巢原理。但也有容斥原理。</li><li>棋盘多项式。有禁区的排列。</li><li>Ramsey数，低概率。</li></ol><p>第四章、Burnside引理与Polya定理</p><ol><li>只考Polya定理，Burnside引理能解决的Polya定理也能干。</li></ol><p>第五章、区组设计</p><ol><li><p>什么是拉丁方，如何构造拉丁方？</p></li><li><p>（b，v，r，k，朗达）</p><p><img src="images/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6/image-20220111165410730.png" alt="image-20220111165410730"></p></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
